{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f64d5aa4-2eb2-4429-9098-0c01d92ed943",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import sp_syllabler\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.metrics.distance import edit_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a0bb8b27-0cf3-4849-bdb5-a8ea2bba33ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "# evaluation for ox\n",
    "with open('data/ox/x_val_ortho.pkl', 'rb') as file:\n",
    "    x_val_ortho = pickle.load(file)\n",
    "\n",
    "with open('data/ox/y_val.pkl', 'rb') as file:\n",
    "    y_val = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d007baa1-be24-4ebe-bb56-1178363ca328",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('data/x_val_ortho.pkl', 'rb') as file:\n",
    "    x_val_ortho = pickle.load(file)\n",
    "    \n",
    "with open('data/x_val_ipa.pkl', 'rb') as file:\n",
    "    x_val_ipa = pickle.load(file)\n",
    "\n",
    "with open('data/y_val.pkl', 'rb') as file:\n",
    "    y_val = pickle.load(file)\n",
    "    \n",
    "with open('data/x_tr_ortho.pkl', 'rb') as file:\n",
    "    x_tr_ortho = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "332c661c-a831-430d-bd87-371cb5bcd85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "# set up for mw eval\n",
    "# ortho max encoder len = 45\n",
    "# ipa max encoder len = 74\n",
    "\n",
    "with open('data/ox/e2i_ortho.pkl', 'rb') as file:\n",
    "    e2i_ortho = pickle.load(file)\n",
    "\n",
    "shitter = sp_syllabler(e2i_ortho= e2i_ortho, ortho_input_size=20,latent_dim=32,embed_dim=32 ,max_feat=36)\n",
    "shitter.model.load_weights('data/ox/single_pen_best_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872fad00-95ba-4400-9829-1e9d02674830",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ortho max encoder len = 45\n",
    "#ipa max encoder len = 74\n",
    "\n",
    "with open('data/e2i_ortho.pkl', 'rb') as file:\n",
    "    e2i_ortho = pickle.load(file)\n",
    "    \n",
    "with open('data/e2i_ipa.pkl', 'rb') as file:\n",
    "    e2i_ipa = pickle.load(file)\n",
    "\n",
    "double_penetrator = dp_syllabler(e2i_ortho= e2i_ortho, e2i_ipa = e2i_ipa, ortho_input_size=45,ipa_input_size=74,latent_dim=32,embed_dim=32 ,max_feat=148)\n",
    "double_penetrator.model.load_weights('data/32_false_double_pen_best_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3e5cf597-4424-4917-8d9a-eb98849585c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_brier(attempted, probability):\n",
    "    total = 0\n",
    "    sum_brier = 0\n",
    "    for word in attempted:\n",
    "        for c in attempted:\n",
    "            total += 1\n",
    "            if c == 2:\n",
    "                sum_brier += (probability - 1)**2\n",
    "            elif c == 1:\n",
    "                sum_brier += (probability - 0)**2\n",
    "    return (1./total)*(sum_brier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ba37d7ae-d302-4cd7-a63d-8fce51e9b56e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3\n",
    "\n",
    "def calc_f1(attempted, true, filename = 'data/ox/evaluation_output_single_pen.txt'):\n",
    "    true_pos = 0\n",
    "    true_neg = 0\n",
    "    false_pos = 0\n",
    "    false_neg = 0\n",
    "    correct_num_char = 0\n",
    "    total_checked = 0\n",
    "    evaluation_file = open(filename, 'w+')\n",
    "    for i in range(0, len(attempted)):\n",
    "        total_checked += 1\n",
    "        if (len(attempted[i]) == len(true[i])):\n",
    "            correct_num_char += 1\n",
    "            for j in range(0, len(attempted[i])):\n",
    "                if(attempted[i][j] == true[i][j]):\n",
    "                    if true[i][j] == 1:\n",
    "                        true_neg += 1\n",
    "                    elif true[i][j] == 2:\n",
    "                        true_pos += 1\n",
    "                else:\n",
    "                    if true[i][j] == 1:\n",
    "                        false_pos += 1\n",
    "                    elif true[i][j] == 2:\n",
    "                        false_neg += 1\n",
    "    evaluation_file.write(\"Total checked: \" + str(total_checked) + '\\n')\n",
    "    evaluation_file.write(\"Num correctly evaluated character count: \" +  str(correct_num_char) + '\\n')\n",
    "    evaluation_file.write(\"True positives: \" + str(true_pos) + '\\n')\n",
    "    evaluation_file.write(\"True negatives: \" + str(true_neg) + '\\n')\n",
    "    evaluation_file.write(\"False positives: \" + str(false_pos) + '\\n')\n",
    "    evaluation_file.write(\"False negatives: \" + str(false_neg) + '\\n')\n",
    "    brier = calc_brier(attempted, probability=0.2)\n",
    "    precision = true_pos/(true_pos+false_pos)\n",
    "    recall = true_pos/(true_pos + false_neg)\n",
    "    f_one = 2/((1/precision)+(1/recall))\n",
    "    evaluation_file.write(\"precision: \" + str(precision) + '\\n')\n",
    "    evaluation_file.write(\"recall: \" + str(recall) +  '\\n')\n",
    "    evaluation_file.write(\"F1 scores: \" + str(f_one) + '\\n')\n",
    "    evaluation_file.write(\"Brier score: \" + str(brier) + '\\n')\n",
    "    evaluation_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3e720948-dc54-458b-b8ea-e76505bb89ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "\n",
    "reals = []\n",
    "for x in y_val:\n",
    "    reals += [[i for i in x if i !=0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a2ee3e95-0514-4e94-b439-e9dde951296f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500\n"
     ]
    }
   ],
   "source": [
    "print(len(x_val_ortho))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce64d07a-97e0-452e-855b-9b4dfda0cb51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6499\r"
     ]
    }
   ],
   "source": [
    "# 5\n",
    "# running through all data points\n",
    "\n",
    "attempts = []\n",
    "for i in range(0, len(x_val_ortho)):\n",
    "    attempts += [shitter.raw_syllabify(x_val_ortho[i])]\n",
    "    print(i, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5129ebca-d138-4be6-b50c-a0afd73faea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6\n",
    "\n",
    "attempts_stripped = []\n",
    "for x in attempts:\n",
    "    attempts_stripped += [[i for i in x if i !=0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ee990122-bd1b-49d6-b55b-169903f5ba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7\n",
    "\n",
    "def inconsistency_grab(attempts, reals, filename = 'data/ox/incorrect_syls.txt'):\n",
    "    global converted_back_to_eng\n",
    "    sum_lev = 0\n",
    "    incorrect_counter = 0\n",
    "    incorrect_syl_count = 0\n",
    "    file = open(filename, 'w+', encoding='utf-8')\n",
    "    file.write('Attempt' + '\\t' + 'Real' + '\\n')\n",
    "    for i in range(0, len(attempts)):\n",
    "        if attempts[i] != reals[i]:\n",
    "            incorrect_counter += 1\n",
    "            a = shitter.insert_syl(converted_back_to_eng[i], attempts[i])\n",
    "            r = shitter.insert_syl(converted_back_to_eng[i], reals[i])\n",
    "            if len(a.split('-')) != len(r.split('-')):\n",
    "                incorrect_syl_count += 1\n",
    "            sum_lev += edit_distance(a,r,substitution_cost=1, transpositions=True)\n",
    "            file.write(a + '\\t' + r + '\\n')\n",
    "    file.write(\"Words with errors: %i\"%incorrect_counter +'\\n')\n",
    "    file.write(\"Words with incorrect number of syllables: %i\"%incorrect_syl_count +'\\n')\n",
    "    file.write(\"Total evluated: %i\"%len(attempts) +'\\n')\n",
    "    file.write(\"Perfect accuracy: %.2f\"%((len(attempts) - incorrect_counter)/len(attempts)) +'\\n')\n",
    "    file.write(\"Number of syllables accuracy: %.2f\"%((len(attempts) - incorrect_syl_count)/len(attempts)) +'\\n')\n",
    "    file.write(\"Average Levenshtein Distance(across incorrect words): %.2f\"%(sum_lev/incorrect_counter) +'\\n')\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "638b60d0-bf6f-4f3a-b7ac-7fa382ef3cd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 8\n",
    "\n",
    "converted_back_to_eng = []\n",
    "for x in x_val_ortho:\n",
    "    real_word = \"\"\n",
    "    for i in x:\n",
    "            if i != 0:\n",
    "                real_word += list(e2i_ortho.keys())[list(e2i_ortho.values()).index(i)]\n",
    "    converted_back_to_eng += [real_word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c971de7-c80b-4a36-add8-b56544905def",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 9 converting attempts to english with hyphens\n",
    "\n",
    "eng_conv_attempts = []\n",
    "for i in range(0, len(attempts)):\n",
    "    eng_conv_attempts += [shitter.insert_syl(converted_back_to_eng[i], attempts[i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "37787f43-c2b4-4a0f-a91f-3b225df26c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 calculation call mw\n",
    "\n",
    "calc_f1(attempts_stripped, reals)\n",
    "inconsistency_grab(attempts_stripped, reals, 'data/ox/incorrect_syls.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae52e7c2-4bd1-4fc1-bb26-458a1612c89d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "calc_f1(attempts_stripped, reals, 'data/32_pure_false_evaluation_output.txt')\n",
    "inconsistency_grab(attempts_stripped, reals, 'data/32_incorrect_syls.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf653dcb-d244-4cf6-9607-ba23b152addd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# testing with falses\n",
    "attempts_prime = []\n",
    "for i in range(0, 5000):\n",
    "    attempts_prime += [double_penetrator.raw_syllabify(x_val_ortho[i], np.array(false_ipa[i]))]\n",
    "    print(i, end='\\r')\n",
    "    \n",
    "attempts_prime_stripped = []\n",
    "for x in attempts_prime:\n",
    "    attempts_prime_stripped += [[i for i in x if i !=0]]\n",
    "    \n",
    "calc_f1(attempts_prime_stripped, reals, 'data/falses_evaluation_output_double_pen.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1d5f0a-4de6-49dc-9e34-8b2ca9776a52",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('data/eng_words.txt','w+') as file:\n",
    "    for i in range(0,5000):\n",
    "        file.write(converted_back_to_eng[i] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca6bb72-8c73-4d85-8d51-0fd162836152",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# falsing training data\n",
    "tr_converted_back_to_eng = []\n",
    "for x in x_tr_ortho:\n",
    "    real_word = \"\"\n",
    "    for i in x:\n",
    "            if i != 0:\n",
    "                real_word += list(e2i_ortho.keys())[list(e2i_ortho.values()).index(i)]\n",
    "    tr_converted_back_to_eng += [real_word]\n",
    "\n",
    "\n",
    "false_ipa_orig = []\n",
    "false_ipa = []\n",
    "\n",
    "for i in range(0,len(x_tr_ortho)):\n",
    "    tried = []\n",
    "    for q in tr_converted_back_to_eng[i]:\n",
    "        tried += l2i[q]\n",
    "    false_ipa_orig += [tried]\n",
    "    \n",
    "for x in false_ipa_orig:\n",
    "    inted = []\n",
    "    for y in x:\n",
    "        inted += [e2i_ipa[y]]\n",
    "    false_ipa += [inted]\n",
    "        \n",
    "    \n",
    "false_ipa = pad_sequences(false_ipa, maxlen=74, padding='post')\n",
    "\n",
    "with open('data/false_ipa.pkl', 'wb+') as file:\n",
    "    pickle.dump(false_ipa, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468fecc7-c253-450f-a667-df5750d0dbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0\n",
    "\n",
    "l2i = {'a':'æ', 'b':'b', 'c':'k', 'd':'d', 'e':'e', 'f':'f' , 'g':'g', 'h':'h', 'i':'ɪ', 'j':'ʒ', 'k':'k', 'l':'l', 'm':'m', 'n':'n',\n",
    "      'o':'ɑ', 'p':'p', 'q':'k', 'r':'ɹ', 's':'s', 't':'t', 'u':'ə', 'v':'v', 'w':'w', 'x':['k','s'], 'y':'j', 'z':'z'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2db8d28d-080d-4205-8f2d-42b602c80647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "6\n",
      "---------------\n",
      "12\n",
      "6\n",
      "---------------\n",
      "9\n",
      "7\n",
      "---------------\n",
      "11\n",
      "6\n",
      "---------------\n",
      "11\n",
      "12\n",
      "---------------\n",
      "6\n",
      "7\n",
      "---------------\n",
      "8\n",
      "10\n",
      "---------------\n",
      "5\n",
      "4\n",
      "---------------\n",
      "8\n",
      "7\n",
      "---------------\n",
      "15\n",
      "6\n",
      "---------------\n",
      "13\n",
      "11\n",
      "---------------\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "length_mismatches = []\n",
    "mismatch_indexes = []\n",
    "\n",
    "for i in range(0, len(attempts_stripped)):\n",
    "    if len(attempts_stripped[i]) != len(reals[i]):\n",
    "        print(len(attempts_stripped[i]))\n",
    "        print(len(reals[i]))\n",
    "        print('---------------')\n",
    "        mismatch_indexes += [i]\n",
    "print(len(mismatch_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4852e951-6920-4af2-ba71-14f87cdd587f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signers\n",
      "7\n",
      "6\n",
      "[1, 1, 2, 1, 1, 1, 1]\n",
      "sig-ners\n",
      "------------\n",
      "typographers\n",
      "12\n",
      "6\n",
      "[1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1]\n",
      "ty-pog-ra-ph-ers\n",
      "------------\n",
      "attempted\n",
      "9\n",
      "7\n",
      "[1, 2, 1, 1, 1, 1, 2, 1, 1]\n",
      "at-tempt-ed\n",
      "------------\n",
      "desirabilia\n",
      "11\n",
      "6\n",
      "[1, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1]\n",
      "de-sir-a-bil-i-a\n",
      "------------\n",
      "collectively\n",
      "11\n",
      "12\n",
      "[1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1]\n",
      "col-lec-tive-ly\n",
      "------------\n",
      "collide\n",
      "6\n",
      "7\n",
      "[1, 1, 2, 1, 1, 1]\n",
      "col-lide\n",
      "------------\n",
      "collective\n",
      "8\n",
      "10\n",
      "[1, 1, 2, 1, 1, 2, 1, 1]\n",
      "col-lec-tive\n",
      "------------\n",
      "based\n",
      "5\n",
      "4\n",
      "[1, 1, 1, 1, 1]\n",
      "based\n",
      "------------\n",
      "burnings\n",
      "8\n",
      "7\n",
      "[1, 1, 1, 2, 1, 1, 1, 1]\n",
      "burn-ings\n",
      "------------\n",
      "suburbanisation\n",
      "15\n",
      "6\n",
      "[1, 1, 2, 1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1]\n",
      "sub-ur-ban-i-sa-tion\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "for x in mismatch_indexes[:10]:\n",
    "    print(converted_back_to_eng[x])\n",
    "    print(len(attempts_stripped[x]))\n",
    "    print(len(reals[x]))\n",
    "    print(attempts_stripped[x])\n",
    "    print(eng_conv_attempts[x])\n",
    "    print('------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ea3a56-16f6-4dd0-8a83-a9772a4eb972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "722481d1-988b-4fa7-bc46-93a3e2283bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "81cb3d47-57aa-450f-9625-6c4248aa0379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31acbce7-34be-40b8-8f09-6bc83df5838f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
