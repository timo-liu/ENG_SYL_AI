{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b4425c2-da36-46cb-ad55-78f687d29943",
   "metadata": {},
   "source": [
    "# Overview of Notebook\n",
    "I don't believe scraping from the oxford dictionary is necessarily conforming to an ethical standard, so I will try and find a dataset to validate the myph datset other than the scraped oxford dictionary.\n",
    "\n",
    "I'm primarily looking for a human curated dataset.\n",
    "\n",
    "I'm going to the use the curated dataset from [DelphiForFun](http://www.delphiforfun.org/programs/Syllables.htm), by Gary D. Darby (God rest his soul). Darby used the mhyph dataset to generate a set of rules for syllabification. A limitation of his work is that his syllabification algorithm is not capable of syllabifying all English words, or pseudowords.\n",
    "\n",
    "I'm going to use my syllabification network, trained on his dataset, for a more robust system of syllabification, one that is ethically sourced this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f88c6923-c9c5-4760-8a9e-d4a7f1890b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "# imports\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd83ba3c-4179-4845-9c99-3c1943dd93a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "# helper functions\n",
    "\n",
    "def convert_to_hot(syl_word, split_token):\n",
    "    hot = []\n",
    "    i = 0\n",
    "    while  i < len(syl_word):\n",
    "        if i == len(syl_word) - 1:\n",
    "            hot += [1]\n",
    "            return hot\n",
    "        if syl_word[i+1] == split_token:\n",
    "            hot += [2]\n",
    "            i += 2\n",
    "        else:\n",
    "            hot += [1]\n",
    "            i += 1\n",
    "    return hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "276cd28f-c2fb-4381-9914-6350052568f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "# environment constants\n",
    "\n",
    "data_raw = 'data/Syllables.txt'\n",
    "train_size = 8000\n",
    "dev_size = 1000\n",
    "test_size = 1000\n",
    "\n",
    "output_directory = 'preprocessed'\n",
    "\n",
    "split_token = 'Â·'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ae836f7-61e2-430c-bc19-6c1962d7476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "# open the file, shuffle and sample\n",
    "\n",
    "with open(data_raw, 'r', encoding='ISO-8859-1') as file:\n",
    "    raw = [line.strip('\\n').split('=') for line in file.readlines()]\n",
    "    random.shuffle(raw)\n",
    "    train = raw[:train_size]\n",
    "    dev = raw[train_size: train_size + dev_size]\n",
    "    test = raw[train_size + dev_size: train_size + dev_size + test_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8225ac89-1937-4cbf-bece-9a507b090b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5\n",
    "# extracted train, dev, test, format into x,y with one hot\n",
    "xtr = [x for x,y in train]\n",
    "ytr = [convert_to_hot(y, split_token) for x,y in train]\n",
    "\n",
    "xdev = [x for x,y in dev]\n",
    "ydev = [convert_to_hot(y, split_token) for x,y in dev]\n",
    "\n",
    "xte = [x for x,y in test]\n",
    "yte = [convert_to_hot(y, split_token) for x,y in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "725eddd7-3f14-4212-b52f-00914ec871c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "# 6\n",
    "# seting hyperparameters based on the data\n",
    "x_raw = [x for x,_ in raw]\n",
    "\n",
    "max_encoder_len = len(max(x_raw, key=len))\n",
    "print(max_encoder_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67879a62-956e-4bc8-a592-114f411dad1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
