{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d98636c-9a39-457e-8443-e79dd4d6ef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf90dc18-b0f8-422a-99b6-510a41f6610a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1\n",
    "\n",
    "def convert_to_hot(syl_word):\n",
    "    hot = []\n",
    "    i = 0\n",
    "    while  i < len(syl_word):\n",
    "        if i == len(syl_word) - 1:\n",
    "            hot += [1]\n",
    "            return hot\n",
    "        if syl_word[i+1] == '-':\n",
    "            hot += [2]\n",
    "            i += 2\n",
    "        else:\n",
    "            hot += [1]\n",
    "            i += 1\n",
    "    return hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03afe84a-380a-47d2-964b-26215314ff40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "# data prep on Ox\n",
    "\n",
    "training_data_size = 20000\n",
    "e2i_vocab_ortho = []\n",
    "e2i_vocab_ipa = []\n",
    "\n",
    "x_tr_ortho = []\n",
    "x_tr_ipa = []\n",
    "y_tr = []\n",
    "\n",
    "x_val_ortho = []\n",
    "x_val_ipa = []\n",
    "y_val = []\n",
    "\n",
    "orig_file = open('data/post_clean.txt')\n",
    "\n",
    "orig_data = orig_file.readlines()\n",
    "orig_file.close()\n",
    "orig_data = [line.strip('\\n') for line in orig_data]\n",
    "random.shuffle(orig_data)\n",
    "data_eng = [line.split(';')[0].lower() for line in orig_data]\n",
    "data_syl = [line.split(';')[1].lower() for line in orig_data]\n",
    "\n",
    "\n",
    "max_encoder_len_ortho = len(max(data_eng, key=len))\n",
    "print(max_encoder_len_ortho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4084dc8-1e40-402b-a059-c16834baae21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3\n",
    "\n",
    "y_tr = []\n",
    "\n",
    "for line in data_eng:\n",
    "    for c in line:\n",
    "        if c not in e2i_vocab_ortho:\n",
    "            e2i_vocab_ortho += [c]\n",
    "            \n",
    "e2i_ortho = dict((a,i) for i,a in enumerate(e2i_vocab_ortho, 1))\n",
    "\n",
    "for line in data_eng[:training_data_size]:\n",
    "    converted = []\n",
    "    for c in line:\n",
    "        converted += [e2i_ortho[c]]\n",
    "    x_tr_ortho += [converted]\n",
    "    \n",
    "x_tr_ortho = pad_sequences(x_tr_ortho, maxlen=20, padding='post')\n",
    "\n",
    "for line in data_syl[:training_data_size]:\n",
    "    y_tr += [convert_to_hot(line)]\n",
    "\n",
    "y_tr = pad_sequences(y_tr, maxlen=20, padding='post')\n",
    "\n",
    "\n",
    "x_tr_file_ortho = open('data/ox/x_tr_ortho.pkl','wb')\n",
    "pickle.dump(x_tr_ortho, x_tr_file_ortho)\n",
    "x_tr_file_ortho.close()\n",
    "\n",
    "y_tr_file = open('data/ox/y_tr.pkl','wb')\n",
    "pickle.dump(y_tr, y_tr_file)\n",
    "y_tr_file.close()\n",
    "\n",
    "e2i_ortho_file = open('data/ox/e2i_ortho.pkl','wb')\n",
    "pickle.dump(e2i_ortho, e2i_ortho_file)\n",
    "e2i_ortho_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "606929bd-8d38-496f-ac44-6d91e4eabf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "# validation data processing\n",
    "\n",
    "x_val_ortho = []\n",
    "x_val_ipa = []\n",
    "y_val = []\n",
    "\n",
    "for line in data_eng[training_data_size:]:\n",
    "    converted = []\n",
    "    for c in line:\n",
    "        converted += [e2i_ortho[c]]\n",
    "    x_val_ortho += [converted]\n",
    "    \n",
    "x_val_ortho = pad_sequences(x_val_ortho, maxlen=20, padding='post')\n",
    "\n",
    "for line in data_syl[training_data_size:]:\n",
    "    y_val += [convert_to_hot(line)]\n",
    "\n",
    "y_val = pad_sequences(y_val, maxlen=20, padding='post')\n",
    "\n",
    "\n",
    "x_val_file_ortho = open('data/ox/x_val_ortho.pkl','wb')\n",
    "pickle.dump(x_val_ortho, x_val_file_ortho)\n",
    "x_val_file_ortho.close()\n",
    "\n",
    "y_val_file = open('data/ox/y_val.pkl','wb')\n",
    "pickle.dump(y_val, y_val_file)\n",
    "y_val_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b770ce25-1c78-438d-ae42-44e9794f8d11",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cross referencing\n",
    "# ¥\n",
    "\n",
    "with open('data/mhyph.txt', encoding=\"ISO-8859-1\") as mhyph:\n",
    "    moby = mhyph.readlines()\n",
    "    moby = [line.strip('\\n') for line in moby]\n",
    "    moby = [(line.replace('¥','').replace('-',''), line.replace('¥','-')) for line in moby if ' ' not in line]\n",
    "    moby_dict = dict(moby)\n",
    "    \n",
    "with open('data/scraped_clean_clean.txt') as ox:\n",
    "    ox_list = ox.readlines()\n",
    "    ox_list = [line.strip('\\n') for line in ox_list]\n",
    "    ox_list = [(line.split(';')[0], line.split(';')[1]) for line in ox_list]\n",
    "    ox_dict = dict(ox_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "139bdc3f-76ca-451a-9460-714c73b05c7c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27644\n",
      "26503\n",
      "['a', 'abandon', 'abandoned', 'ability', 'able']\n",
      "[('a', 'a'), ('abandon', 'a-ban-don'), ('abandoned', 'a-ban-doned'), ('ability', 'a-bil-i-ty'), ('able', 'a-ble')]\n",
      "[('aged', 'a-ged'), ('a-na-lyze', 'an-a-lyse'), ('a-na-ly-sis', 'a-nal-y-sis'), ('a-ni-mal', 'an-i-mal'), ('at-tach', 'at-ta-ch')]\n"
     ]
    }
   ],
   "source": [
    "post_checked = []\n",
    "mismatches = []\n",
    "\n",
    "print(len(ox_dict.keys()))\n",
    "\n",
    "for word in ox_dict.keys():\n",
    "    try:\n",
    "        if ox_dict[word] == moby_dict[word]:\n",
    "            post_checked += [(word, ox_dict[word])]\n",
    "        else:\n",
    "            if word in moby_dict.keys():\n",
    "                mismatches += [(ox_dict[word], moby_dict[word])]\n",
    "    except:\n",
    "        post_checked += [(word, ox_dict[word])]\n",
    "            \n",
    "print(len(post_checked))\n",
    "print(list(ox_dict.keys())[:5])\n",
    "print(post_checked[:5])\n",
    "print(mismatches[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "13218966-3eff-48de-b254-6661adea9780",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(data_syl)):\n",
    "    if data_syl[i].lower() == 'images':\n",
    "        print(data_eng[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a1ff07bb-f334-4a96-bf03-729477fc98ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grabbing data for syllable percentage estimate\n",
    "\n",
    "num_pos = 0\n",
    "num_neg = 0\n",
    "total = 0\n",
    "for word in y_tr:\n",
    "    for c in word:\n",
    "        if c == 2:\n",
    "            num_pos += 1\n",
    "            total += 1\n",
    "        elif c == 1:\n",
    "            num_neg += 1\n",
    "            total += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7b90225c-33a4-4479-a4ee-6490dfe5deaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32871\n",
      "125387\n",
      "158258\n",
      "0.20770513970857712\n"
     ]
    }
   ],
   "source": [
    "print(num_pos)\n",
    "print(num_neg)\n",
    "print(total)\n",
    "print(float(num_pos)/float(total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:laptop_sketchbook] *",
   "language": "python",
   "name": "conda-env-laptop_sketchbook-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
